{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e06309d-e67c-4441-8af4-a035e74c8fd1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prepare data for DsaClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e63a131f-6b07-4f0e-a2b1-057f359c4df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import os\n",
    "import pycountry\n",
    "from natsort import natsorted\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6acdb662-6e17-45ee-a588-3ec52401ec6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ISO codes and rename columns\n",
    "def get_iso_code(country_name):\n",
    "    try:\n",
    "        country = pycountry.countries.search_fuzzy(country_name)[0]\n",
    "        return country.alpha_3\n",
    "    except LookupError:\n",
    "        return country_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa2c0cd-76ed-4951-b135-d603984dbd19",
   "metadata": {},
   "source": [
    "### Create weo df from WEO data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "9acfde8e-a5b7-4eb1-8467-7aaf2a9b27d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in WEO data\n",
    "file_path = '../data/RawData/WEO2023-1all.xls'\n",
    "df_weo = pd.read_excel(file_path)\n",
    "\n",
    "# Drop columns that we don't need from the original data frame.\n",
    "df_weo = df_weo.drop(columns={'WEO Country Code',\n",
    "                              'Country',\n",
    "                              'Subject Descriptor', \n",
    "                              'Subject Notes', \n",
    "                              'Units', \n",
    "                              'Scale', \n",
    "                              'Country/Series-specific Notes', \n",
    "                              'Estimates Start After'})\n",
    "\n",
    "# Reshape the data frame from wide to long format\n",
    "df_weo = df_weo.melt(id_vars=['ISO', 'WEO Subject Code'], var_name='Year', value_name='Value')\n",
    "\n",
    "# Convert Subject Codes to individual columns\n",
    "df_weo = df_weo.groupby(['ISO', 'Year', 'WEO Subject Code'])['Value'].aggregate('first').unstack().reset_index()\n",
    "df_weo['Year'] = df_weo['Year'].astype(int)\n",
    "df_weo = df_weo.rename(columns={'Year':'year'})\n",
    "\n",
    "df_weo.to_csv('../data/InputData/weo_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65cc8b7-e86e-4f3a-8b87-512607dea614",
   "metadata": {},
   "source": [
    "### Create term structure df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e9a535-73e4-4b2e-9fe8-cb491ff244f4",
   "metadata": {},
   "source": [
    "#### Bloomberg debt data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "54014525-2ec8-4dbc-a577-2639f85b6302",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/RawData/bbg_debt_data.xlsx'\n",
    "workbook = pd.ExcelFile(file_path)\n",
    "\n",
    "# Create empty list to store dataframes\n",
    "df_list = []     \n",
    "\n",
    "#Extract each sheet from workbook\n",
    "for sheet in workbook.sheet_names:\n",
    "\n",
    "    df = pd.read_excel(workbook, sheet_name=sheet)\n",
    "    \n",
    "    # Get country names form filename, save as column and create ISO column\n",
    "    df['ISO'] = pycountry.countries.lookup(sheet).alpha_3\n",
    "    \n",
    "    # Drop T-bills \n",
    "    df = df.loc[~df['Issuer Name'].str.contains('Treasury Bill') & (df['Duration'] > 0.6), :]\n",
    "    \n",
    "    # Extract the maturity year from the Maturity column and save it as 'year'\n",
    "    df['year'] = pd.to_datetime(df['Maturity']).dt.year\n",
    "    df['Amt Out'] = df['Amt Out']\n",
    "    df['Cpn'] = df['Cpn'].replace('--',0)\n",
    "    # Calculate coupon amount for each bond\n",
    "    df['coupon'] = df['Amt Out'] * df['Cpn'] / 100\n",
    "    # Add 'Event' column and fill it with 'Principal'\n",
    "    df['Event'] = 'Principal'\n",
    "    \n",
    "    coupons_df = pd.DataFrame()\n",
    "    for i, row in df.iterrows():\n",
    "        # Create a list of years from 2022 to the maturity year of the current bond\n",
    "        maturity_year = row['year']\n",
    "        years_list = list(range(2022, maturity_year + 1))   \n",
    "\n",
    "        # Iterate over each year in the years list\n",
    "        for year in years_list:\n",
    "\n",
    "            # Create a copy of the original row\n",
    "            new_row = row.copy()\n",
    "            # Update the 'year' column with the current year\n",
    "            new_row['year'] = year\n",
    "            # Update the 'Event' column with 'Coupon'\n",
    "            new_row['Event'] = 'Coupon'\n",
    "            # Append the new row to the coupons dataframe\n",
    "            coupons_df = pd.concat([coupons_df, new_row.to_frame().T], ignore_index=True)\n",
    "\n",
    "    # Create a new column 'amount_lc_bn'\n",
    "    df['amount_lc_bn'] = df['Amt Out']\n",
    "    coupons_df['amount_lc_bn'] = coupons_df['coupon']\n",
    "\n",
    "    # Concatenate the original dataframe and the coupons dataframe\n",
    "    df = pd.concat([df, coupons_df], ignore_index=True)\n",
    "\n",
    "    # Group by 'year' and 'Event', and sum the 'amount_lc_bn' column\n",
    "    df = df.groupby(['ISO', 'year', 'Event'])['amount_lc_bn'].sum().reset_index()\n",
    "\n",
    "    # Divide the values in the 'amount_lc_bn' column by 1000000000\n",
    "    df['amount_lc_bn'] = df['amount_lc_bn'] / 1000000000\n",
    "\n",
    "    # Append to list\n",
    "    df_list.append(df)\n",
    "    \n",
    "workbook.close()\n",
    "\n",
    "# merge all dfs from list\n",
    "df_bbg_debt = pd.DataFrame(columns=df.columns)\n",
    "for df in df_list:\n",
    "    df_bbg_debt = pd.concat([df_bbg_debt, df]).reset_index(drop=True)\n",
    "#df_bbg_debt.to_csv('../data/InputData/bbg_term_structure_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ffcbc9-61bb-474f-98b6-6466988f6486",
   "metadata": {},
   "source": [
    "#### Eikon debt data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e272e2ea-ba81-47dc-9487-3f1d97dd48fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all files in the directory\n",
    "file_path = '../data/RawData/Debt_Data_Eikon/'\n",
    "filenames = os.listdir(file_path)\n",
    "\n",
    "# Create empty list to store dataframes\n",
    "df_list = []     \n",
    "\n",
    "# define regular expressions for coupon rate and date\n",
    "coupon_regex = r'(?P<coupon_rate>\\d+\\.\\d{3})'\n",
    "\n",
    "# Iterate over filenames to read in excel workbooks\n",
    "for filename in filenames:     \n",
    "    path = f'{file_path}{filename}'\n",
    "    df = pd.read_excel(path, skiprows=1)  \n",
    "    \n",
    "    # Get country names form filename, save as column and create ISO column\n",
    "    country = filename.split('.')[0]\n",
    "    df['ISO'] = pycountry.countries.lookup(country).alpha_3\n",
    "    \n",
    "    # apply regular expressions to description column to get dates and coupon rates\n",
    "    #df['coupon_rate'] = df['Description'].str.extract(coupon_regex)\n",
    "\n",
    "    # Append to list\n",
    "    df_list.append(df)\n",
    "    \n",
    "# merge all dfs from list\n",
    "df_eikon_debt = pd.DataFrame(columns=df.columns)\n",
    "for df in df_list:\n",
    "    df_eikon_debt = pd.concat([df_eikon_debt, df]).reset_index(drop=True)\n",
    "\n",
    "df_eikon_debt = df_eikon_debt.drop(columns={'Description',\n",
    "                                                    'Currency',\n",
    "                                                    'RIC',\n",
    "                                                    'ISIN',\n",
    "                                                    'Issue Type',\n",
    "                                                    'Amount, USD'})\n",
    "df_eikon_debt = df_eikon_debt.rename(columns={'Date':'year', 'Native Amount':'amount_lc_bn'})\n",
    "\n",
    "df_eikon_debt['year'] = df_eikon_debt['year'].astype(str).str[:4].replace(['NaT', 'nan'], '9999').astype(int)\n",
    "df_eikon_debt['amount_lc_bn'] = df_eikon_debt['amount_lc_bn'] / 1000000000\n",
    "df_eikon_debt = df_eikon_debt.groupby(['ISO','year','Event']).sum().reset_index()\n",
    "#df_eikon_debt.to_csv('../data/InputData/term_structure_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c8fd2b37-3829-40f9-92fb-3d87ca0a305e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bbg_debt = df_bbg_debt.loc[~df_bbg_debt['ISO'].isin(['GRC', 'HRV'])]\n",
    "df_term_structure = pd.concat([df_eikon_debt, df_bbg_debt])\n",
    "df_term_structure.to_csv('../data/InputData/term_structure_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34918939-ab03-4bd1-b043-fa7cb6e8b61b",
   "metadata": {},
   "source": [
    "### Create ESM EFSF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "23aaae72-afbe-433e-9288-1ee00314308e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/RawData/esm_efsf_data.xlsx'\n",
    "df_esm = pd.read_excel(file_path).T\n",
    "\n",
    "df_esm_amount = df_esm.iloc[2:,[0,2,4]].reset_index()\n",
    "df_esm_amount.columns = ['year', 'GRC', 'PRT', 'IRL']\n",
    "df_esm_amount = df_esm_amount.melt(id_vars=['year'], var_name='ISO', value_name='amount')\n",
    "\n",
    "df_esm_rate = df_esm.iloc[2:,[1,3,5]].reset_index()\n",
    "df_esm_rate.columns = ['year', 'GRC', 'PRT', 'IRL']\n",
    "df_esm_rate = df_esm_rate.melt(id_vars=['year'], var_name='ISO', value_name='rate')\n",
    "\n",
    "df_esm = df_esm_amount.merge(df_esm_rate, on = ['year', 'ISO'])\n",
    "df_esm['interest'] = df_esm['amount'] * df_esm['rate'] / 100\n",
    "for ISO in ['GRC', 'PRT', 'IRL']:\n",
    "    df_esm.loc[df_esm['ISO'] == ISO, 'amortization'] = df_esm.loc[df_esm['ISO'] == ISO, 'amount'].shift(periods=1, axis=0) - df_esm.loc[df_esm['ISO'] == ISO, 'amount']\n",
    "df_esm.to_csv('../data/InputData/esm_efsf_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a361241-277c-432c-8896-9f742d267d8c",
   "metadata": {},
   "source": [
    "### Create interest rate df from Bloomberg data (old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf385ea-a256-468d-8902-c546198bc640",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/RawData/gov_bonds_full.xlsx'\n",
    "workbook = pd.ExcelFile(file_path)\n",
    "\n",
    "# Create empty list to store dataframes\n",
    "df_list = []     \n",
    "\n",
    "#Extract each sheet from workbook\n",
    "for sheet in workbook.sheet_names[2:]:\n",
    "    df = pd.read_excel(workbook, sheet_name=sheet, skiprows=2)\n",
    "    \n",
    "    # Add bond_type column and keep only latest entry\n",
    "    df['bond_type'] = sheet\n",
    "    df = df.iloc[[-1]]\n",
    "    # Append to list\n",
    "    df_list.append(df)\n",
    "workbook.close()\n",
    "\n",
    "# Save base_year of fwd rates\n",
    "base_year = int(pd.to_datetime(df.iloc[:,0]).dt.year)\n",
    "\n",
    "# Join fwd rate series to new DataFrame\n",
    "df_fwd_rates = pd.DataFrame(columns=df.columns)\n",
    "for df in df_list:\n",
    "    df_fwd_rates = pd.concat([df_fwd_rates, df]).reset_index(drop=True)  \n",
    "\n",
    "# convert to format with bond types as columns    \n",
    "df_fwd_rates = df_fwd_rates.iloc[:,1:].set_index('bond_type').T.reset_index(names='country').dropna(subset=['country'])\n",
    "\n",
    "# Add ISO codes and rename columns\n",
    "def get_iso_code(country_name):\n",
    "    try:\n",
    "        country = pycountry.countries.search_fuzzy(country_name)[0]\n",
    "        return country.alpha_3\n",
    "    except LookupError:\n",
    "        return np.nan\n",
    "\n",
    "df_fwd_rates['ISO'] = df_fwd_rates['country'].apply(get_iso_code)\n",
    "df_fwd_rates['base_year'] = base_year\n",
    "\n",
    "df_fwd_rates = df_fwd_rates.rename(columns={\n",
    "    '5Y10Y fwd gvt bonds': '5Y10Y', \n",
    "    '10Y15Y fwd gvt bonds': '10Y15Y',\n",
    "    '10Y20Y fwd gvt bonds': '10Y20Y',\n",
    "    '10Y25Y fwd gvt bonds': '10Y25Y',\n",
    "    '10Y30Y fwd gvt bonds': '10Y30Y'\n",
    "})\n",
    "\n",
    "df_fwd_rates.to_csv('../data/InputData/fwd_rates_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827ec18c-58d9-45f6-8b26-8ac96dcdc9e7",
   "metadata": {},
   "source": [
    "### Create ECB debt data df via api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71208dcc-4062-4f66-a04f-cd1246784109",
   "metadata": {},
   "source": [
    "#### Shares of short term debt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2d60b67-7160-4df4-8f58-43b6e9a5aa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_code_dict = {\n",
    "    'AT': 'AUT',\n",
    "    'BE': 'BEL',\n",
    "    'BG': 'BGR',\n",
    "    #'CY': 'CYP',\n",
    "    'CZ': 'CZE',\n",
    "    'DE': 'DEU',\n",
    "    'DK': 'DNK',\n",
    "    #'EE': 'EST',\n",
    "    'ES': 'ESP',\n",
    "    'FI': 'FIN',\n",
    "    'FR': 'FRA',\n",
    "    'GR': 'GRC',\n",
    "    'HR': 'HRV',\n",
    "    'HU': 'HUN',\n",
    "    'IE': 'IRL',\n",
    "    'IT': 'ITA',\n",
    "    'LT': 'LTU',\n",
    "    #'LU': 'LUX',\n",
    "    'LV': 'LVA',\n",
    "    #'MT': 'MLT',\n",
    "    'NL': 'NLD',\n",
    "    'PL': 'POL',\n",
    "    'PT': 'PRT',\n",
    "    'RO': 'ROU',\n",
    "    'SE': 'SWE',\n",
    "    'SI': 'SVN',\n",
    "    'SK': 'SVK'\n",
    "}\n",
    "\n",
    "data_dict = {}\n",
    "\n",
    "for country_key in country_code_dict:\n",
    "    \n",
    "    data_dict[country_code_dict[country_key]] = {}\n",
    "    \n",
    "    series_key_dict = {'total_securities':f'GFS/M.N.{country_key}.W0.S13.S1.N.L.LE.F3.T._Z.EUR._T.F.V.N._T',\n",
    "                       'long_term':f'GFS/M.N.{country_key}.W0.S13.S1.N.L.LE.F3.LL._Z.EUR._T.F.V.N._T',\n",
    "                       'long_short_term':f'GFS/M.N.{country_key}.W0.S13.S1.N.L.LE.F3.LS._Z.EUR._T.F.V.N._T',\n",
    "                       'short_term':f'GFS/M.N.{country_key}.W0.S13.S1.N.L.LE.F3.S._Z.EUR._T.F.V.N._T'}\n",
    "    \n",
    "    for series_key in series_key_dict:\n",
    "        \n",
    "        url = 'https://sdw-wsrest.ecb.europa.eu/service/data/'\n",
    "        headers = {'Accept':'application/json'}\n",
    "        r = requests.get(f'{url}{series_key_dict[series_key]}', headers=headers).json()\n",
    "        date_list = r['structure']['dimensions']['observation'][0]['values']\n",
    "\n",
    "        data_dict[country_code_dict[country_key]][series_key] = {}\n",
    "\n",
    "        for i, j in enumerate(date_list):\n",
    "            date = r['structure']['dimensions']['observation'][0]['values'][i]['id']\n",
    "            obs = r['dataSets'][0]['series']['0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0']['observations'][str(i)][0]\n",
    "            data_dict[country_code_dict[country_key]][series_key][date] = obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eabffc1f-6e48-41f4-af1c-f1ebe7a89e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [pd.DataFrame.from_dict(values, orient='index', columns=['value'])\n",
    "       .reset_index()\n",
    "       .rename(columns={'index': 'year'})\n",
    "       .assign(ISO=iso, type=t)\n",
    "       for iso, types in data_dict.items()\n",
    "       for t, values in types.items()]\n",
    "\n",
    "df_ecb = pd.concat(dfs, ignore_index=True)[['ISO', 'type', 'year', 'value']]\n",
    "df_ecb = df_ecb[df_ecb['year'].str.endswith('-12')].replace('-12', '', regex=True)\n",
    "df_ecb['value'] = df_ecb['value']/1000\n",
    "\n",
    "\n",
    "df_ecb.to_csv('../data/InputData/ecb_debt_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb23ed42-27c7-4f5b-8fe5-cf102089dfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/InputData/ecb_debt_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "383f8fbd-ad7a-4dbe-b1ec-e161509a4193",
   "metadata": {},
   "outputs": [],
   "source": [
    "share_st = []\n",
    "share_sst_list = []\n",
    "\n",
    "share_st_list = []\n",
    "for iso in df.ISO.unique():\n",
    "    df_ecb = df.loc[(df['ISO'] == iso)]\n",
    "\n",
    "    ecb_base_year = df_ecb['year'].iloc[-1] # Last year with ECB data\n",
    "\n",
    "    ecb_total = float(df_ecb.loc[(df_ecb['year'] == ecb_base_year) & (df_ecb['type'] == 'total_securities'), 'value']) # Total security debt\n",
    "    ecb_lst = float(df_ecb.loc[(df_ecb['year'] == ecb_base_year) & (df_ecb['type'] == 'long_short_term'), 'value']) # Total security debt        \n",
    "    ecb_sst = float(df_ecb.loc[(df_ecb['year'] == ecb_base_year) & (df_ecb['type'] == 'short_term'), 'value'])  # short-term security debt (m<1y)\n",
    "    share_st = (ecb_sst + ecb_lst) / ecb_total\n",
    "    share_sst = ecb_sst / ecb_total\n",
    "    share_lt = 1 - share_sst\n",
    "    share_st_list.append(share_st)\n",
    "    share_sst_list.append(share_sst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "52bf51e1-59d1-4669-b40e-5b27a70d445d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average share of short term debt is 0.045167253581310865\n"
     ]
    }
   ],
   "source": [
    "print(f'Average share of short term debt is {np.mean(share_sst_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "015f81fc-35c3-4b3a-b8db-825d05fe8141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average share of debt with res. mat <1 is 0.13429386763844137\n"
     ]
    }
   ],
   "source": [
    "print(f'Average share of debt with res. mat <1 is {np.mean(share_st_list)}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b26baf-adfa-4972-aa37-ecef082f440f",
   "metadata": {},
   "source": [
    "#### ECB short term gov interest rate 2nd of year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "85be8d97-65d0-4e31-9abe-d4b96f564282",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {}\n",
    "\n",
    "for country_key in country_code_dict:\n",
    "    \n",
    "    data_dict[country_code_dict[country_key]] = {}\n",
    "    series_keyf'GFS/M.N.{country_key}.W0.S13.S1.N.L.LE.F3A.TS._Z.RT._T.F.V.A1._T'}\n",
    "    \n",
    "    for series_key in series_key_dict:\n",
    "        \n",
    "        url = 'https://sdw-wsrest.ecb.europa.eu/service/data/'\n",
    "        headers = {'Accept':'application/json'}\n",
    "        r = requests.get(f'{url}{series_key_dict[series_key]}', headers=headers).json()\n",
    "        date_list = r['structure']['dimensions']['observation'][0]['values']\n",
    "\n",
    "        data_dict[country_code_dict[country_key]][series_key] = {}\n",
    "\n",
    "        for i, j in enumerate(date_list):\n",
    "            date = r['structure']['dimensions']['observation'][0]['values'][i]['id']\n",
    "            obs = r['dataSets'][0]['series']['0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0:0']['observations'][str(i)][0]\n",
    "            data_dict[country_code_dict[country_key]][series_key][date] = obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2252d6f7-7508-485c-826f-538942181821",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lennard.welslau\\AppData\\Local\\Temp\\ipykernel_23840\\358968811.py:10: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_1Y_rates = df_1Y_rates.groupby(['ISO','year']).mean().reset_index()\n"
     ]
    }
   ],
   "source": [
    "dfs = [pd.DataFrame.from_dict(values, orient='index', columns=['value'])\n",
    "       .reset_index()\n",
    "       .rename(columns={'index': 'year'})\n",
    "       .assign(ISO=iso, type=t)\n",
    "       for iso, types in data_dict.items()\n",
    "       for t, values in types.items()]\n",
    "df_1Y_rates = pd.concat(dfs, ignore_index=True)[['ISO', 'type', 'year', 'value']].dropna(subset='value')\n",
    "df_1Y_rates = df_1Y_rates[df_1Y_rates['year'].str[-2:].astype(int)>6]\n",
    "df_1Y_rates['year'] = df_1Y_rates['year'].str[:-3].astype(int)\n",
    "df_1Y_rates = df_1Y_rates.groupby(['ISO','year']).mean().reset_index()\n",
    "#df_1Y_rates = df_1Y_rates.loc[df_1Y_rates['year'] == df_1Y_rates['year'].unique().max()]\n",
    "df_1Y_rates.to_csv('../data/InputData/ecb_st_rate_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e71c075-7833-44e8-affc-61db2fc10dad",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create interest rate df from Bloomberg data (full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "40357cf8-b833-4993-b8f9-4e397db87149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary from the 'country' column of df_bbg_codes\n",
    "bbg_dict = pd.read_excel('../data/RawData/bbg_gov_fwd_rates.xlsx', sheet_name='BBG GOV CODES').set_index('code')\n",
    "bbg_dict = bbg_dict.to_dict()['country']\n",
    "\n",
    "# Read the Excel file into a dataframe, select relevant data\n",
    "df_fwd_rates = pd.read_excel('../data/RawData/bbg_gov_fwd_rates.xlsx', sheet_name='BBG - gov_fwd_rates (2)', skiprows=3).iloc[-1].reset_index()\n",
    "df_fwd_rates = df_fwd_rates.iloc[1:].rename(columns={'index':'bond_type', 189:'value'})\n",
    "\n",
    "# Get country and bond_type info\n",
    "df_fwd_rates['ISO'] = df_fwd_rates['bond_type'].astype(str).str[0:5].map(bbg_dict)\n",
    "df_fwd_rates['bond_type'] = df_fwd_rates['bond_type'].astype(str).str.split(' ').str[1]\n",
    "\n",
    "# Pivot the data to have bond types as columns and ISO codes as rows\n",
    "df_fwd_rates = df_fwd_rates.pivot_table(values='value', index='ISO', columns='bond_type').reset_index()\n",
    "df_fwd_rates['ISO'] = df_fwd_rates['ISO'].astype(str).apply(get_iso_code)\n",
    "\n",
    "# Sort the columns using natsorted and save df\n",
    "df_fwd_rates = df_fwd_rates.set_index('ISO')\n",
    "df_fwd_rates = df_fwd_rates[natsorted(df_fwd_rates.columns)].reset_index()\n",
    "\n",
    "df_fwd_rates.to_csv('../data/InputData/fwd_rates_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58d5dc2-525e-492a-bd0f-b3dacba5c840",
   "metadata": {},
   "source": [
    "### Create Inflation swap data df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "a4c2645f-a937-4021-a63b-cedf3ec1bb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_inflation_expectation(df_maturity_1):\n",
    "    df_maturity_2 = df_maturity_1.shift(1)\n",
    "    \n",
    "    # Calculate the annualized prices of the two swaps\n",
    "    annualized_price_swap1 = (1 + df_maturity_1['value'] / 100) ** df_maturity_1['maturity']\n",
    "    annualized_price_swap2 = (1 + df_maturity_2['value'] / 100) ** df_maturity_2['maturity']\n",
    "    \n",
    "    # Calculate the implied inflation rate\n",
    "    inflation_rate = (((annualized_price_swap2 / annualized_price_swap1) ** (1 / (df_maturity_2['maturity'] - df_maturity_1['maturity']))) - 1 ) * 100\n",
    "    inflation_rate[1] = df_maturity_1['value'].iloc[0] \n",
    "    \n",
    "    # Return the implied inflation rate\n",
    "    return pd.DataFrame(inflation_rate).astype(float).set_index(df_maturity_1['maturity']).reset_index().rename(columns={0:'infl_expectation'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "c88400b2-1355-4585-9e12-1a653a0dfe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fwd_infl = pd.read_excel('../data/RawData/infl_fwd_swap.xlsx', sheet_name='BBG - infl swap zero coupon', skiprows=3).iloc[-1].reset_index()\n",
    "df_fwd_infl = df_fwd_infl.iloc[1:].rename(columns={'index':'maturity', 189:'value'})\n",
    "df_fwd_infl['maturity'] = df_fwd_infl['maturity'].astype(str).str.replace('EUSWI','').astype(str).str.split(' ').str[0].astype(int)\n",
    "df_fwd_infl = calculate_inflation_expectation(df_fwd_infl)\n",
    "\n",
    "# Add missing years by interpolating linearly\n",
    "for i in range(1,31):\n",
    "    if i in df_fwd_infl['maturity'].to_list():\n",
    "        continue\n",
    "    else:\n",
    "        df = pd.DataFrame([[i,np.nan]], columns=df_fwd_infl.columns)\n",
    "        df_fwd_infl = pd.concat([df_fwd_infl, df], axis=0)\n",
    "df_fwd_infl = df_fwd_infl.sort_values(by='maturity').reset_index(drop=True)\n",
    "df_fwd_infl = df_fwd_infl.interpolate()\n",
    "\n",
    "df_fwd_infl.to_csv('../data/InputData/infl_expectatation.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
